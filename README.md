# Food Classification ğŸ½ï¸

Projeto de classificaÃ§Ã£o de alimentos utilizando Deep Learning com PyTorch e ResNet-50.

## ğŸ“‹ DescriÃ§Ã£o

Este projeto implementa um classificador de alimentos utilizando tÃ©cnicas avanÃ§adas de Deep Learning. O modelo Ã© baseado na arquitetura ResNet-50 prÃ©-treinada no ImageNet, com fine-tuning e otimizaÃ§Ãµes especÃ­ficas para melhorar a acurÃ¡cia na classificaÃ§Ã£o de diferentes tipos de pratos.

## ğŸ¯ Objetivo

Desenvolver um modelo de classificaÃ§Ã£o de imagens capaz de identificar diferentes tipos de alimentos com alta precisÃ£o, aplicando tÃ©cnicas de transfer learning e data augmentation para melhorar a generalizaÃ§Ã£o.

## ğŸ“Š Dataset

O projeto utiliza o **Food-41 Dataset** disponÃ­vel no Kaggle:
- **Fonte:** [Food-41 Dataset (Kaggle)](https://www.kaggle.com/kmader/food41)
- **NÃºmero de classes:** 41 categorias diferentes de alimentos
- **Download:** Realizado automaticamente via `kagglehub`

### DivisÃ£o dos Dados
- **Treino:** 80% do dataset
- **ValidaÃ§Ã£o:** 20% do dataset
- **OpÃ§Ã£o de subset:** Possibilidade de treinar com um subset menor (ex: 5000 imagens) para testes mais rÃ¡pidos

## ğŸ—ï¸ Arquitetura do Modelo

### Modelo Base: ResNet-50

O projeto utiliza uma ResNet-50 prÃ©-treinada com as seguintes caracterÃ­sticas:

```
Modelo: ResNet-50 (prÃ©-treinado no ImageNet)
â”œâ”€â”€ Camadas Congeladas:
â”‚   â”œâ”€â”€ conv1, bn1 (camadas iniciais)
â”‚   â”œâ”€â”€ layer1 (bloco residual 1)
â”‚   â””â”€â”€ layer2 (bloco residual 2)
â”œâ”€â”€ Camadas TreinÃ¡veis:
â”‚   â”œâ”€â”€ layer3 (bloco residual 3)
â”‚   â””â”€â”€ layer4 (bloco residual 4)
â””â”€â”€ Classificador Personalizado:
    â”œâ”€â”€ Dropout(0.5)
    â”œâ”€â”€ Linear(2048 â†’ 512)
    â”œâ”€â”€ ReLU
    â”œâ”€â”€ Dropout(0.3)
    â””â”€â”€ Linear(512 â†’ num_classes)
```

### EspecificaÃ§Ãµes TÃ©cnicas
- **ResoluÃ§Ã£o de entrada:** 224x224 pixels
- **NormalizaÃ§Ã£o:** ImageNet mean/std ([0.485, 0.456, 0.406] / [0.229, 0.224, 0.225])
- **Batch size:** 32
- **Device:** CUDA (GPU) ou CPU

## ğŸ”„ Data Augmentation

### TransformaÃ§Ãµes de Treino
Para melhorar a generalizaÃ§Ã£o do modelo, sÃ£o aplicadas as seguintes tÃ©cnicas:

- **Resize:** 224x224 pixels
- **RandomHorizontalFlip:** p=0.5
- **RandomRotation:** Â±20 graus
- **ColorJitter:** brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1
- **RandomAffine:** translaÃ§Ã£o de atÃ© 10%
- **RandomPerspective:** distortion_scale=0.2, p=0.5
- **NormalizaÃ§Ã£o:** ImageNet standards

### TransformaÃ§Ãµes de ValidaÃ§Ã£o
- **Resize:** 224x224 pixels
- **NormalizaÃ§Ã£o:** ImageNet standards (sem augmentation)

## âš™ï¸ ConfiguraÃ§Ã£o do Treinamento

### Otimizador e HiperparÃ¢metros

| ParÃ¢metro | Valor |
|-----------|-------|
| **Otimizador** | Adam |
| **Learning Rate** | 0.0001 |
| **Weight Decay** | 1e-4 |
| **Scheduler** | ReduceLROnPlateau (patience=3, factor=0.5) |
| **Loss Function** | CrossEntropyLoss com Label Smoothing (0.1) |
| **Ã‰pocas MÃ¡ximas** | 50 |
| **Early Stopping** | Patience de 10 Ã©pocas |

### EstratÃ©gias de RegularizaÃ§Ã£o
- **Dropout:** 0.5 na primeira camada FC, 0.3 na segunda
- **Weight Decay:** L2 regularization (1e-4)
- **Label Smoothing:** 0.1 para evitar overconfidence

## ğŸ“ˆ Resultados

### Melhorias Implementadas

| Componente | Melhoria |
|------------|----------|
| **Modelo** | ResNet-50 (mais profundo e robusto) |
| **ResoluÃ§Ã£o** | 224x224 pixels (padrÃ£o ImageNet) |
| **Fine-tuning** | Layer3 e Layer4 treinÃ¡veis |
| **Data Augmentation** | ColorJitter, RandomAffine, RandomPerspective |
| **Learning Rate** | 0.0001 com ReduceLROnPlateau |
| **RegularizaÃ§Ã£o** | Weight Decay (1e-4), Dropout (0.5 e 0.3) |
| **Loss Function** | CrossEntropyLoss com Label Smoothing (0.1) |
| **Early Stopping** | Patience de 10 Ã©pocas |
| **Ã‰pocas** | AtÃ© 50 (com early stopping) |

### Performance Esperada
- **AcurÃ¡cia Anterior:** ~42%
- **AcurÃ¡cia Esperada:** 65-75%
- **ObservaÃ§Ã£o:** Tempo de treinamento mais longo, mas com melhor generalizaÃ§Ã£o

## ğŸš€ Como Usar

### PrÃ©-requisitos

```bash
pip install torch torchvision kagglehub matplotlib numpy
```

### InstalaÃ§Ã£o

1. Clone o repositÃ³rio:
```bash
git clone https://github.com/Andre-Quintela/Food-Classification.git
cd Food-Classification
```

2. Execute o notebook:
```bash
jupyter notebook Classificacao_de_Pratos.ipynb
```

### Executando o Projeto

O notebook estÃ¡ organizado nas seguintes seÃ§Ãµes:

1. **Download do Dataset:** Baixa automaticamente o Food-41 via kagglehub
2. **PreparaÃ§Ã£o dos Dados:** Carrega e aplica transformaÃ§Ãµes
3. **DefiniÃ§Ã£o do Modelo:** Cria a arquitetura ResNet-50 customizada
4. **ConfiguraÃ§Ã£o do Treinamento:** Define otimizador e scheduler
5. **Treinamento:** Executa o loop de treinamento com early stopping
6. **VisualizaÃ§Ã£o dos Resultados:** Plots de loss e acurÃ¡cia
7. **PrediÃ§Ãµes:** Exemplos de classificaÃ§Ã£o em imagens do conjunto de validaÃ§Ã£o

### Ajustando o Tamanho do Dataset

Para testes mais rÃ¡pidos, vocÃª pode reduzir o tamanho do dataset:

```python
subset_size = 5000  # Use None para dataset completo
```

Valores sugeridos: 5000, 10000, 20000, ou None para o dataset completo.

## ğŸ“ Estrutura do Projeto

```
Food-Classification/
â”œâ”€â”€ Classificacao_de_Pratos.ipynb  # Notebook principal com todo o pipeline
â””â”€â”€ README.md                       # Este arquivo
```

## ğŸ› ï¸ Tecnologias Utilizadas

- **Python 3.x**
- **PyTorch:** Framework de Deep Learning
- **TorchVision:** Modelos e transformaÃ§Ãµes de imagens
- **KaggleHub:** Download automÃ¡tico de datasets
- **Matplotlib:** VisualizaÃ§Ã£o de resultados
- **NumPy:** OperaÃ§Ãµes numÃ©ricas

## ğŸ“Š VisualizaÃ§Ãµes

O projeto gera as seguintes visualizaÃ§Ãµes:

1. **Curvas de Treinamento:**
   - Loss de treino vs validaÃ§Ã£o
   - AcurÃ¡cia de treino vs validaÃ§Ã£o

2. **Exemplos de PrediÃ§Ãµes:**
   - Imagens de validaÃ§Ã£o com prediÃ§Ãµes e labels verdadeiros
   - VisualizaÃ§Ã£o de acertos e erros do modelo

## ğŸ¤ Contribuindo

ContribuiÃ§Ãµes sÃ£o bem-vindas! Sinta-se Ã  vontade para:

1. Fazer um fork do projeto
2. Criar uma branch para sua feature (`git checkout -b feature/AmazingFeature`)
3. Commit suas mudanÃ§as (`git commit -m 'Add some AmazingFeature'`)
4. Push para a branch (`git push origin feature/AmazingFeature`)
5. Abrir um Pull Request

## ğŸ“ LicenÃ§a

Este projeto estÃ¡ sob uma licenÃ§a aberta. Sinta-se livre para usar e modificar.

## ğŸ‘¤ Autor

**Andre Quintela**

- GitHub: [@Andre-Quintela](https://github.com/Andre-Quintela)

## ğŸ™ Agradecimentos

- Dataset Food-41 disponibilizado por kmader no Kaggle
- Comunidade PyTorch pelos excelentes recursos e documentaÃ§Ã£o
- Arquitetura ResNet desenvolvida por Microsoft Research
